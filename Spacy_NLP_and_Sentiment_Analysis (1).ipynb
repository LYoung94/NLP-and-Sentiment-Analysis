{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xQ97R-XMKkB"
      },
      "outputs": [],
      "source": [
        "pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YVW-PEAw_idQ"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.cli import download\n",
        "\n",
        "def main():\n",
        "    # Check if the model is installed, if not, download it\n",
        "    if not spacy.util.is_package(\"en_core_web_sm\"):\n",
        "        print(\"Downloading the English model...\")\n",
        "        download(\"en_core_web_sm\")\n",
        "\n",
        "    # Load spaCy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJEScmND_Ntl"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "def main():\n",
        "    # Load the spaCy model (you might need to download the model first)\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # Sample text for processing\n",
        "    text = \"SpaCy is an awesome NLP library. It provides fast and efficient text processing capabilities.\"\n",
        "\n",
        "    # Process the text using spaCy NLP pipeline\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Tokenization\n",
        "    print(\"Tokenization:\")\n",
        "    for token in doc:\n",
        "        print(token.text)\n",
        "\n",
        "    # Part-of-speech tagging\n",
        "    print(\"\\nPart-of-speech tagging:\")\n",
        "    for token in doc:\n",
        "        print(f\"{token.text} - {token.pos_}\")\n",
        "\n",
        "    # Named Entity Recognition (NER)\n",
        "    print(\"\\nNamed Entity Recognition:\")\n",
        "    for ent in doc.ents:\n",
        "        print(f\"{ent.text} - {ent.label_}\")\n",
        "\n",
        "    # Dependency parsing\n",
        "    print(\"\\nDependency parsing:\")\n",
        "    for token in doc:\n",
        "        print(f\"{token.text} - {token.dep_} - {token.head.text}\")\n",
        "\n",
        "    # Lemmatization\n",
        "    print(\"\\nLemmatization:\")\n",
        "    for token in doc:\n",
        "        print(f\"{token.text} - {token.lemma_}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7udNcSwXFagb"
      },
      "source": [
        "Code for full text sentiment analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngCB4lqEFc4Q"
      },
      "outputs": [],
      "source": [
        "pip install vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eXlyzrxcFgCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df58feb0-93a5-473e-d180-1ad42939d65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Scores: {'neg': 0.101, 'neu': 0.547, 'pos': 0.352, 'compound': 0.73}\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "# Download the VADER lexicon\n",
        "nltk.download(\"vader_lexicon\")\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Create a SentimentIntensityAnalyzer object from VADER\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Perform sentiment analysis using spaCy and VADER\n",
        "def perform_sentiment_analysis(text):\n",
        "    # Calculate sentiment scores using VADER for the entire text\n",
        "    score = analyzer.polarity_scores(text)\n",
        "    return score\n",
        "\n",
        "def main():\n",
        "    sample_text = \"I dont really like tacos, but overrall I love Hispanic food.\"\n",
        "\n",
        "    # Perform sentiment analysis on the entire text\n",
        "    sentiment_score = perform_sentiment_analysis(sample_text)\n",
        "\n",
        "    # Print sentiment score for the entire text\n",
        "    print(\"Sentiment Scores:\", sentiment_score)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfjLtc_-GpKA"
      },
      "source": [
        "Each sentence is analyzed separately:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uh1CjdwGnFv"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "# Download the VADER lexicon\n",
        "nltk.download(\"vader_lexicon\")\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Add the sentencizer component to the pipeline\n",
        "if \"sentencizer\" not in nlp.pipe_names:\n",
        "    nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "# Create a SentimentIntensityAnalyzer object from VADER\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Perform sentiment analysis using spaCy and VADER\n",
        "def perform_sentiment_analysis(text):\n",
        "    # Tokenize and process the text using spaCy\n",
        "    doc = nlp(text)\n",
        "    sentences = [sent.text for sent in doc.sents]\n",
        "\n",
        "    # Calculate sentiment scores using VADER for each sentence\n",
        "    sentiment_scores = []\n",
        "    for sentence in sentences:\n",
        "        score = analyzer.polarity_scores(sentence)\n",
        "        sentiment_scores.append(score)\n",
        "\n",
        "    return sentiment_scores\n",
        "\n",
        "def main():\n",
        "    sample_text = \"I hate art. I like art. I love art. I would eat art. art is cool.\"\n",
        "\n",
        "    # Perform sentiment analysis on the sample text\n",
        "    sentiment_scores = perform_sentiment_analysis(sample_text)\n",
        "\n",
        "    # Print sentiment scores for each sentence\n",
        "    for i, sentence_score in enumerate(sentiment_scores):\n",
        "        print(f\"Sentence {i+1} - Sentiment Scores: {sentence_score}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}